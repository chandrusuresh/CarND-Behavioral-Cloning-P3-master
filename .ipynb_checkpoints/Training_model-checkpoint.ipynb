{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from numpy.random import shuffle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "\n",
    "cwd = os.getcwd()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----------------\n",
    "# Data processing\n",
    "#-----------------\n",
    "\n",
    "# Load data\n",
    "data_path = './data/' # AWS instance\n",
    "# data_path = './complete_training_set/' # AWS instance\n",
    "\n",
    "img_path = data_path+'IMG/'\n",
    "csv_file = data_path+'driving_log.csv'\n",
    "\n",
    "# read the CSV file into a list\n",
    "samples = []\n",
    "with open(csv_file) as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader) # skip 1st line, in case it's a header line\n",
    "    for line in reader:\n",
    "        samples.append(line)\n",
    "\n",
    "# split out the validation dataset\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "\n",
    "# offset camera steering function\n",
    "# Attempt to provide more correction when steering AWAY from camera,\n",
    "# and less correction when towards camera\n",
    "def steering_corr(steer):\n",
    "    b = 0.25\n",
    "    return b\n",
    "\n",
    "#set image color space\n",
    "colorspace = cv2.COLOR_BGR2RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generator function that acturally reads the image(s), on demand / as needed\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "#         shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "\n",
    "                # center camera\n",
    "                img_name = img_path+batch_sample[0].split('/')[-1]\n",
    "                center_image = cv2.cvtColor(cv2.imread(img_name), colorspace)\n",
    "                center_angle = float(batch_sample[3])\n",
    "\n",
    "                # left camera\n",
    "                img_name = img_path+batch_sample[1].split('/')[-1]\n",
    "                left_image = cv2.cvtColor(cv2.imread(img_name), colorspace)\n",
    "                left_angle = center_angle + steering_corr(center_angle)\n",
    "                left_angle = min(max(left_angle, -1.0), 1.0)\n",
    "\n",
    "                # right camera\n",
    "                img_name = img_path+batch_sample[2].split('/')[-1]\n",
    "                right_image = cv2.cvtColor(cv2.imread(img_name), colorspace)\n",
    "                right_angle = center_angle - steering_corr(-center_angle)\n",
    "                right_angle = min(max(right_angle, -1.0), 1.0)\n",
    "\n",
    "                # append data from cameras\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "\n",
    "            X_train_orig = np.array(images)\n",
    "            y_train_orig = np.array(angles)\n",
    "\n",
    "            # create flipped image data as well\n",
    "            X_train_flip = np.array(np.fliplr(images))\n",
    "            y_train_flip =-np.array(angles)\n",
    "\n",
    "            X_train = np.concatenate((X_train_orig, X_train_flip), axis=0)\n",
    "            y_train = np.concatenate((y_train_orig, y_train_flip), axis=0)\n",
    "\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# instantiate generators\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n",
    "# determine the input image shape\n",
    "# by looking at 1st frame's center image\n",
    "img_name = img_path+train_samples[0][0].split('/')[-1]\n",
    "image0 = cv2.cvtColor(cv2.imread(img_name), colorspace)\n",
    "imshape = image0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "14166/14166 [==============================] - 34s - loss: 0.0462 - val_loss: 0.0420\n",
      "Epoch 2/6\n",
      "14166/14166 [==============================] - 33s - loss: 0.0373 - val_loss: 0.0386\n",
      "Epoch 3/6\n",
      "14166/14166 [==============================] - 33s - loss: 0.0341 - val_loss: 0.0358\n",
      "Epoch 4/6\n",
      "14166/14166 [==============================] - 33s - loss: 0.0321 - val_loss: 0.0330\n",
      "Epoch 5/6\n",
      "14166/14166 [==============================] - 33s - loss: 0.0298 - val_loss: 0.0326\n",
      "Epoch 6/6\n",
      "14166/14166 [==============================] - 33s - loss: 0.0287 - val_loss: 0.0311\n"
     ]
    }
   ],
   "source": [
    "#------------------\n",
    "# Model definition\n",
    "#------------------\n",
    "\n",
    "# based upon Nvidia paper:\n",
    "# http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Flatten, Dense, Lambda\n",
    "# from keras.layers import MaxPooling2D, Dropout, Cropping2D\n",
    "# from keras.layers.convolutional import Conv2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: ((x/255.0)-0.5),\n",
    "                 input_shape=imshape,\n",
    "                 name='lambda'))\n",
    "model.add(Cropping2D(cropping=((50,20),(0,0)),\n",
    "                     name='crop'))\n",
    "# model.add(AveragePooling2D(pool_size=(1,4), name=\"Resize\", trainable=False))\n",
    "model.add(Conv2D(nb_filter=24,\n",
    "                 nb_row=5,\n",
    "                 nb_col=5,\n",
    "                 subsample=(2,2),\n",
    "                 border_mode='valid',\n",
    "                 activation='relu',\n",
    "                 name='conv1'))\n",
    "# model.add(MaxPooling2D(name=\"MaxPool1\"))\n",
    "model.add(Conv2D(nb_filter=36,\n",
    "                 nb_row=5,\n",
    "                 nb_col=5,\n",
    "                 subsample=(2,2),\n",
    "                 border_mode='valid',\n",
    "                 activation='relu',\n",
    "                 name='conv2'))\n",
    "# model.add(MaxPooling2D(name=\"MaxPool2\"))\n",
    "model.add(Conv2D(nb_filter=48,\n",
    "                 nb_row=5,\n",
    "                 nb_col=5,\n",
    "                 subsample=(2,2),\n",
    "                 border_mode='valid',\n",
    "                 activation='relu',\n",
    "                 name='conv3'))\n",
    "# model.add(MaxPooling2D(name=\"MaxPool3\"))\n",
    "model.add(Conv2D(nb_filter=64,\n",
    "                 nb_row=3,\n",
    "                 nb_col=3,\n",
    "                 subsample=(1,1),\n",
    "                 border_mode='valid',\n",
    "                 activation='relu',\n",
    "                 name='conv4'))\n",
    "# model.add(MaxPooling2D(name=\"MaxPool4\"))\n",
    "model.add(Conv2D(nb_filter=64,\n",
    "                 nb_row=3,\n",
    "                 nb_col=3,\n",
    "                 subsample=(1,1),\n",
    "                 border_mode='valid',\n",
    "                 activation='relu',\n",
    "                 name='conv5'))\n",
    "model.add(MaxPooling2D(name=\"MaxPool5\"))\n",
    "model.add(Flatten(name='flat'))\n",
    "model.add(Dropout(0.5, name='dropout'))\n",
    "# model.add(Dense(256, activation='elu', name='dense0'))\n",
    "model.add(Dense(100, activation='relu', name='dense1'))\n",
    "model.add(Dense(50, activation='relu', name='dense2'))\n",
    "model.add(Dense(10, activation='relu', name='dense3'))\n",
    "model.add(Dense(1, name='output'))\n",
    "\n",
    "# model compilation\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# set up Model checkpoint saving callback\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "save_filename = 'model_Dean_50pcDropout_relu_maxPooling.h5'\n",
    "checkpoint = ModelCheckpoint(save_filename,\n",
    "                             monitor='val_loss',\n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False)\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# train the model\n",
    "history_obj =  model.fit_generator(train_generator,\n",
    "                                   samples_per_epoch=len(train_samples)*6,\n",
    "                                   validation_data=validation_generator,\n",
    "                                   nb_val_samples=len(validation_samples)*6,\n",
    "                                   nb_epoch=6,\n",
    "                                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'drive.py', 'examples', 'model_run4.h5', 'model_run5.h5', 'P3_solution.html', 'P3_solution.ipynb', 'README.md', 'Training_model.ipynb', 'Training_video.mp4', 'video.py', 'writeup_template.md']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(cwd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
